{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import pickle\n",
    "import torch\n",
    "import torchvision\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(123)\n",
    "np.random.seed(123)\n",
    "torch.manual_seed(123)\n",
    "torch.cuda.manual_seed(123)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TripletNet(torch.nn.Module):\n",
    "    \"\"\"Triplet Network.\"\"\"\n",
    "\n",
    "    def __init__(self, embeddingnet):\n",
    "        \"\"\"Triplet Network Builder.\"\"\"\n",
    "        super(TripletNet, self).__init__()\n",
    "        self.embeddingnet = embeddingnet\n",
    "\n",
    "    def forward(self, a, p, n):\n",
    "        \"\"\"Forward pass.\"\"\"\n",
    "        # anchor\n",
    "        embedded_a = self.embeddingnet(a)\n",
    "\n",
    "        # positive examples\n",
    "        embedded_p = self.embeddingnet(p)\n",
    "\n",
    "        # negative examples\n",
    "        embedded_n = self.embeddingnet(n)\n",
    "\n",
    "        return embedded_a, embedded_p, embedded_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv0 = nn.Sequential(\n",
    "            nn.Conv2d(1, 64, (128, 3), padding=(0, 1)),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(64, 64, (1, 3), padding=(0,1)),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, (1, 3), padding=(0,1)),\n",
    "            nn.BatchNorm2d(64)\n",
    "        )\n",
    "\n",
    "        self.skip1 = nn.Sequential(\n",
    "            nn.Conv2d(64, 64, (1, 1)),\n",
    "            nn.BatchNorm2d(64)\n",
    "        )\n",
    "\n",
    "        self.sum1 = nn.Sequential(\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, (1, 3), stride=(1,2), padding=(0,1)),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(128, 128, (1, 3), padding=(0,1)),\n",
    "            nn.BatchNorm2d(128)\n",
    "        )\n",
    "\n",
    "        self.skip2 = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, (1, 1), stride=(1,2)),\n",
    "            nn.BatchNorm2d(128)\n",
    "        )\n",
    "\n",
    "        self.sum2 = nn.Sequential(\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv2d(128, 256, (1, 3), stride=(1,2), padding=(0,1)),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(256, 256, (1, 3), padding=(0,1)),\n",
    "            nn.BatchNorm2d(256)\n",
    "        )\n",
    "\n",
    "        self.skip3 = nn.Sequential(\n",
    "            nn.Conv2d(128, 256, (1, 1), stride=(1,2)),\n",
    "            nn.BatchNorm2d(256)\n",
    "        )\n",
    "\n",
    "        self.sum3 = nn.Sequential(\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.conv4 = nn.Sequential(\n",
    "            nn.Conv2d(256, 512, (1, 3), stride=(1,2), padding=(0,1)),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(512, 512, (1, 3), padding=(0,1)),\n",
    "            nn.BatchNorm2d(512)\n",
    "        )\n",
    "\n",
    "        self.skip4 = nn.Sequential(\n",
    "            nn.Conv2d(256, 512, (1, 1), stride=(1,2)),\n",
    "            nn.BatchNorm2d(512)\n",
    "        )\n",
    "\n",
    "        self.sum4 = nn.Sequential(\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.global_pooling = nn.AvgPool2d((1, 156))\n",
    "\n",
    "        self.dense = nn.Linear(512, 4096)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x0 = self.conv0(x)\n",
    "        x1 = self.sum1(self.conv1(x0) + self.skip1(x0))\n",
    "        x2 = self.sum2(self.conv2(x1) + self.skip2(x1))\n",
    "        x3 = self.sum3(self.conv3(x2) + self.skip3(x2))\n",
    "        x4 = self.sum4(self.conv4(x3) + self.skip4(x3))\n",
    "        x5 = self.global_pooling(x4)\n",
    "\n",
    "        x6 = x5.view(x5.shape[0], -1)\n",
    "        x7 = self.dense(x6)\n",
    "        return x7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('../data/pickles/models/custom_resnet_27.12.0.16.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "embd_net = model.embeddingnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageFolderWithPaths(torchvision.datasets.ImageFolder):\n",
    "    def __getitem__(self, index):\n",
    "        original_tuple = super(ImageFolderWithPaths, self).__getitem__(index)\n",
    "        path = self.imgs[index][0]\n",
    "        tuple_with_path = (original_tuple + (path,))\n",
    "        return tuple_with_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize training set together with augmentation\n",
    "one_transform = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=1),\n",
    "#     transforms.Resize((224,224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.0069], [0.0033])\n",
    "])\n",
    "\n",
    "train_dir = '../data/spectrograms/train/train/'\n",
    "val_dir = '../data/spectrograms/train/val/'\n",
    "test_dir = '../data/spectrograms/test/'\n",
    "\n",
    "batch_size = 16\n",
    "test_dataset = ImageFolderWithPaths(test_dir, one_transform)\n",
    "test_dataloader = torch.utils.data.DataLoader(\n",
    "    test_dataset, batch_size=batch_size, shuffle=False, num_workers=8\n",
    ")\n",
    "\n",
    "train_dataset = ImageFolderWithPaths(train_dir, one_transform)\n",
    "val_dataset = ImageFolderWithPaths(val_dir, one_transform)\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "    train_dataset, batch_size=batch_size, shuffle=False, drop_last=False, num_workers=8\n",
    ")\n",
    "val_dataloader = torch.utils.data.DataLoader(\n",
    "    val_dataset, batch_size=batch_size, shuffle=False, num_workers=8\n",
    ")\n",
    "\n",
    "# class_names = train_dataset.classes\n",
    "\n",
    "\n",
    "# Loading Tiny ImageNet dataset\n",
    "# trplt_path = '../pickles_for_git/triplets.p'\n",
    "# batch_szie = 32\n",
    "# trainset = TripletDataset(triplet_path=trplt_path, transform=one_transform)\n",
    "# trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_szie, num_workers=8)\n",
    "\n",
    "# testset = TripletImageLoader(\n",
    "#     base_path=root, triplets_filename=\"\", transform=transform_test, train=False)\n",
    "# testloader = torch.utils.data.DataLoader(\n",
    "#     testset, batch_size=batch_size_test, num_workers=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7, 97)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_dataloader), len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, test_loader):\n",
    "    with torch.no_grad():\n",
    "        logits = []\n",
    "    \n",
    "        for inputs, x, path in test_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            model.eval()\n",
    "            outputs = model(inputs).cpu()\n",
    "            logits.append(outputs)\n",
    "            \n",
    "    probs = torch.nn.functional.softmax(torch.cat(logits), dim=-1).numpy()\n",
    "    return probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "embd_net = embd_net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    logits = []\n",
    "\n",
    "    for inputs, x, path in test_dataloader:\n",
    "        inputs = inputs.to(device)\n",
    "        embd_net.eval()\n",
    "        outputs = embd_net(inputs).cpu()\n",
    "        logits.append(outputs)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4096])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    logits = []\n",
    "    path_list = list()\n",
    "    for inputs, x, path in test_dataloader:\n",
    "        inputs = inputs.to(device)\n",
    "        embd_net.eval()\n",
    "        outputs = embd_net(inputs).cpu()\n",
    "        logits.append(outputs)\n",
    "        path_list.append(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "#     logits = []\n",
    "#     path_list = list()\n",
    "    for inputs, x, path in val_dataloader:\n",
    "        inputs = inputs.to(device)\n",
    "        embd_net.eval()\n",
    "        outputs = embd_net(inputs).cpu()\n",
    "        logits.append(outputs)\n",
    "        path_list.append(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "#     logits = []\n",
    "#     path_list = list()\n",
    "    for inputs, x, path in train_dataloader:\n",
    "        inputs = inputs.to(device)\n",
    "        embd_net.eval()\n",
    "        outputs = embd_net(inputs).cpu()\n",
    "        logits.append(outputs)\n",
    "        path_list.append(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../data/spectrograms/test/unknown/000190.png'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_list[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4096"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits[0][0].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_list = list()\n",
    "for i in logits:\n",
    "    for tens in i:\n",
    "        emb_list.append(tens.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = pd.DataFrame(emb_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "track_list = list()\n",
    "for i in path_list:\n",
    "    for path in i:\n",
    "        name = path.split('/')[-1]\n",
    "        ids = name.split('.')[0]\n",
    "        track_list.append(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings['id'] = track_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = embeddings[['id'] + list(np.arange(logits[0][0].shape[0]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>4086</th>\n",
       "      <th>4087</th>\n",
       "      <th>4088</th>\n",
       "      <th>4089</th>\n",
       "      <th>4090</th>\n",
       "      <th>4091</th>\n",
       "      <th>4092</th>\n",
       "      <th>4093</th>\n",
       "      <th>4094</th>\n",
       "      <th>4095</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000190</td>\n",
       "      <td>0.239317</td>\n",
       "      <td>-0.397095</td>\n",
       "      <td>0.066670</td>\n",
       "      <td>-0.112857</td>\n",
       "      <td>0.267753</td>\n",
       "      <td>-0.052551</td>\n",
       "      <td>0.096670</td>\n",
       "      <td>-0.045432</td>\n",
       "      <td>0.172941</td>\n",
       "      <td>...</td>\n",
       "      <td>0.062273</td>\n",
       "      <td>-0.054813</td>\n",
       "      <td>-0.580411</td>\n",
       "      <td>-0.060844</td>\n",
       "      <td>0.283575</td>\n",
       "      <td>-0.322482</td>\n",
       "      <td>0.536448</td>\n",
       "      <td>-0.547134</td>\n",
       "      <td>0.435944</td>\n",
       "      <td>-0.009193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000194</td>\n",
       "      <td>0.228010</td>\n",
       "      <td>-0.267925</td>\n",
       "      <td>0.050254</td>\n",
       "      <td>-0.064885</td>\n",
       "      <td>0.204552</td>\n",
       "      <td>-0.129576</td>\n",
       "      <td>0.097313</td>\n",
       "      <td>0.054549</td>\n",
       "      <td>0.160086</td>\n",
       "      <td>...</td>\n",
       "      <td>0.123470</td>\n",
       "      <td>0.036018</td>\n",
       "      <td>-0.554675</td>\n",
       "      <td>-0.084867</td>\n",
       "      <td>0.241101</td>\n",
       "      <td>-0.407837</td>\n",
       "      <td>0.459143</td>\n",
       "      <td>-0.405547</td>\n",
       "      <td>0.325219</td>\n",
       "      <td>0.030739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000667</td>\n",
       "      <td>0.172511</td>\n",
       "      <td>-0.411962</td>\n",
       "      <td>-0.189085</td>\n",
       "      <td>-0.207302</td>\n",
       "      <td>0.240760</td>\n",
       "      <td>-0.356008</td>\n",
       "      <td>-0.125368</td>\n",
       "      <td>0.159223</td>\n",
       "      <td>0.145956</td>\n",
       "      <td>...</td>\n",
       "      <td>0.091740</td>\n",
       "      <td>0.235835</td>\n",
       "      <td>-0.380354</td>\n",
       "      <td>0.122873</td>\n",
       "      <td>0.403869</td>\n",
       "      <td>-0.645875</td>\n",
       "      <td>0.179191</td>\n",
       "      <td>-0.043992</td>\n",
       "      <td>-0.246042</td>\n",
       "      <td>0.162271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>001040</td>\n",
       "      <td>0.082101</td>\n",
       "      <td>-0.374198</td>\n",
       "      <td>-0.069975</td>\n",
       "      <td>-0.125310</td>\n",
       "      <td>0.116177</td>\n",
       "      <td>-0.230725</td>\n",
       "      <td>-0.045782</td>\n",
       "      <td>0.068693</td>\n",
       "      <td>0.189867</td>\n",
       "      <td>...</td>\n",
       "      <td>0.023682</td>\n",
       "      <td>0.061822</td>\n",
       "      <td>-0.319704</td>\n",
       "      <td>-0.105478</td>\n",
       "      <td>0.274142</td>\n",
       "      <td>-0.537587</td>\n",
       "      <td>0.266508</td>\n",
       "      <td>-0.130056</td>\n",
       "      <td>0.051768</td>\n",
       "      <td>0.177883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>001686</td>\n",
       "      <td>0.097401</td>\n",
       "      <td>-0.337461</td>\n",
       "      <td>-0.043460</td>\n",
       "      <td>-0.049395</td>\n",
       "      <td>0.358293</td>\n",
       "      <td>-0.022668</td>\n",
       "      <td>0.214166</td>\n",
       "      <td>-0.157234</td>\n",
       "      <td>0.158639</td>\n",
       "      <td>...</td>\n",
       "      <td>0.095537</td>\n",
       "      <td>0.080308</td>\n",
       "      <td>-0.397135</td>\n",
       "      <td>0.167263</td>\n",
       "      <td>0.297460</td>\n",
       "      <td>-0.427000</td>\n",
       "      <td>0.659261</td>\n",
       "      <td>-0.343497</td>\n",
       "      <td>0.185148</td>\n",
       "      <td>0.160289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7989</th>\n",
       "      <td>149416</td>\n",
       "      <td>0.030924</td>\n",
       "      <td>-0.247550</td>\n",
       "      <td>-0.178629</td>\n",
       "      <td>-0.061112</td>\n",
       "      <td>0.027577</td>\n",
       "      <td>-0.162658</td>\n",
       "      <td>-0.221465</td>\n",
       "      <td>-0.065798</td>\n",
       "      <td>0.129087</td>\n",
       "      <td>...</td>\n",
       "      <td>0.195687</td>\n",
       "      <td>0.089321</td>\n",
       "      <td>-0.291216</td>\n",
       "      <td>-0.142482</td>\n",
       "      <td>0.205989</td>\n",
       "      <td>-0.573224</td>\n",
       "      <td>0.384657</td>\n",
       "      <td>-0.033724</td>\n",
       "      <td>-0.058859</td>\n",
       "      <td>0.158304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7990</th>\n",
       "      <td>149417</td>\n",
       "      <td>0.036764</td>\n",
       "      <td>-0.458351</td>\n",
       "      <td>-0.088213</td>\n",
       "      <td>-0.177309</td>\n",
       "      <td>-0.051371</td>\n",
       "      <td>-0.145914</td>\n",
       "      <td>-0.140578</td>\n",
       "      <td>-0.086203</td>\n",
       "      <td>0.120065</td>\n",
       "      <td>...</td>\n",
       "      <td>0.140031</td>\n",
       "      <td>0.064523</td>\n",
       "      <td>-0.262126</td>\n",
       "      <td>-0.076916</td>\n",
       "      <td>0.275563</td>\n",
       "      <td>-0.584401</td>\n",
       "      <td>0.395788</td>\n",
       "      <td>-0.099448</td>\n",
       "      <td>0.052889</td>\n",
       "      <td>0.137360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7991</th>\n",
       "      <td>149452</td>\n",
       "      <td>0.104525</td>\n",
       "      <td>-0.469663</td>\n",
       "      <td>0.084858</td>\n",
       "      <td>-0.304183</td>\n",
       "      <td>0.086875</td>\n",
       "      <td>-0.330575</td>\n",
       "      <td>-0.015224</td>\n",
       "      <td>-0.085978</td>\n",
       "      <td>0.090347</td>\n",
       "      <td>...</td>\n",
       "      <td>0.128999</td>\n",
       "      <td>0.089443</td>\n",
       "      <td>-0.236963</td>\n",
       "      <td>-0.058777</td>\n",
       "      <td>0.350236</td>\n",
       "      <td>-0.518301</td>\n",
       "      <td>0.177216</td>\n",
       "      <td>-0.213805</td>\n",
       "      <td>-0.100781</td>\n",
       "      <td>0.229377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7992</th>\n",
       "      <td>149488</td>\n",
       "      <td>0.013139</td>\n",
       "      <td>-0.466050</td>\n",
       "      <td>-0.014817</td>\n",
       "      <td>-0.071389</td>\n",
       "      <td>-0.013317</td>\n",
       "      <td>-0.200836</td>\n",
       "      <td>0.081551</td>\n",
       "      <td>-0.161710</td>\n",
       "      <td>-0.112145</td>\n",
       "      <td>...</td>\n",
       "      <td>0.090962</td>\n",
       "      <td>0.241779</td>\n",
       "      <td>-0.107526</td>\n",
       "      <td>-0.191463</td>\n",
       "      <td>0.313202</td>\n",
       "      <td>-0.453634</td>\n",
       "      <td>0.384773</td>\n",
       "      <td>0.071279</td>\n",
       "      <td>-0.046346</td>\n",
       "      <td>0.256486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7993</th>\n",
       "      <td>149523</td>\n",
       "      <td>0.371300</td>\n",
       "      <td>-0.477057</td>\n",
       "      <td>-0.206421</td>\n",
       "      <td>-0.412735</td>\n",
       "      <td>0.104866</td>\n",
       "      <td>-0.290566</td>\n",
       "      <td>0.076054</td>\n",
       "      <td>-0.050893</td>\n",
       "      <td>0.063611</td>\n",
       "      <td>...</td>\n",
       "      <td>0.129957</td>\n",
       "      <td>0.093911</td>\n",
       "      <td>-0.418258</td>\n",
       "      <td>0.039716</td>\n",
       "      <td>0.369140</td>\n",
       "      <td>-0.344529</td>\n",
       "      <td>0.277433</td>\n",
       "      <td>-0.277116</td>\n",
       "      <td>0.082448</td>\n",
       "      <td>0.107276</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7994 rows Ã— 4097 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id         0         1         2         3         4         5  \\\n",
       "0     000190  0.239317 -0.397095  0.066670 -0.112857  0.267753 -0.052551   \n",
       "1     000194  0.228010 -0.267925  0.050254 -0.064885  0.204552 -0.129576   \n",
       "2     000667  0.172511 -0.411962 -0.189085 -0.207302  0.240760 -0.356008   \n",
       "3     001040  0.082101 -0.374198 -0.069975 -0.125310  0.116177 -0.230725   \n",
       "4     001686  0.097401 -0.337461 -0.043460 -0.049395  0.358293 -0.022668   \n",
       "...      ...       ...       ...       ...       ...       ...       ...   \n",
       "7989  149416  0.030924 -0.247550 -0.178629 -0.061112  0.027577 -0.162658   \n",
       "7990  149417  0.036764 -0.458351 -0.088213 -0.177309 -0.051371 -0.145914   \n",
       "7991  149452  0.104525 -0.469663  0.084858 -0.304183  0.086875 -0.330575   \n",
       "7992  149488  0.013139 -0.466050 -0.014817 -0.071389 -0.013317 -0.200836   \n",
       "7993  149523  0.371300 -0.477057 -0.206421 -0.412735  0.104866 -0.290566   \n",
       "\n",
       "             6         7         8  ...      4086      4087      4088  \\\n",
       "0     0.096670 -0.045432  0.172941  ...  0.062273 -0.054813 -0.580411   \n",
       "1     0.097313  0.054549  0.160086  ...  0.123470  0.036018 -0.554675   \n",
       "2    -0.125368  0.159223  0.145956  ...  0.091740  0.235835 -0.380354   \n",
       "3    -0.045782  0.068693  0.189867  ...  0.023682  0.061822 -0.319704   \n",
       "4     0.214166 -0.157234  0.158639  ...  0.095537  0.080308 -0.397135   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "7989 -0.221465 -0.065798  0.129087  ...  0.195687  0.089321 -0.291216   \n",
       "7990 -0.140578 -0.086203  0.120065  ...  0.140031  0.064523 -0.262126   \n",
       "7991 -0.015224 -0.085978  0.090347  ...  0.128999  0.089443 -0.236963   \n",
       "7992  0.081551 -0.161710 -0.112145  ...  0.090962  0.241779 -0.107526   \n",
       "7993  0.076054 -0.050893  0.063611  ...  0.129957  0.093911 -0.418258   \n",
       "\n",
       "          4089      4090      4091      4092      4093      4094      4095  \n",
       "0    -0.060844  0.283575 -0.322482  0.536448 -0.547134  0.435944 -0.009193  \n",
       "1    -0.084867  0.241101 -0.407837  0.459143 -0.405547  0.325219  0.030739  \n",
       "2     0.122873  0.403869 -0.645875  0.179191 -0.043992 -0.246042  0.162271  \n",
       "3    -0.105478  0.274142 -0.537587  0.266508 -0.130056  0.051768  0.177883  \n",
       "4     0.167263  0.297460 -0.427000  0.659261 -0.343497  0.185148  0.160289  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "7989 -0.142482  0.205989 -0.573224  0.384657 -0.033724 -0.058859  0.158304  \n",
       "7990 -0.076916  0.275563 -0.584401  0.395788 -0.099448  0.052889  0.137360  \n",
       "7991 -0.058777  0.350236 -0.518301  0.177216 -0.213805 -0.100781  0.229377  \n",
       "7992 -0.191463  0.313202 -0.453634  0.384773  0.071279 -0.046346  0.256486  \n",
       "7993  0.039716  0.369140 -0.344529  0.277433 -0.277116  0.082448  0.107276  \n",
       "\n",
       "[7994 rows x 4097 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings.to_csv('../data/csv/custom_resnet_triplet_embeddings.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dp_project",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
